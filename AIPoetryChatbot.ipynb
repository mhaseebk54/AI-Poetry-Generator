{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1TADwrcGVOg"
      },
      "outputs": [],
      "source": [
        "!pip install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n"
      ],
      "metadata": {
        "id": "fVApaMPaHJpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
        "prompts = [\n",
        "    \"Describe a futuristic city in 2050.\",\n",
        "    \"Write a motivational quote about learning.\",\n",
        "    \"Explain blockchain in simple terms.\",\n",
        "    \"Write a short dialogue between a robot and a human about friendship.\",\n",
        "    \"Describe the taste of your favorite food in a poetic way.\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "  response = model.generate(prompt)\n",
        "  print(f\"Prompt: {prompt}\\nResponse: {response}\\n\")"
      ],
      "metadata": {
        "id": "ZnRi7SoAHu63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "train_file = \"/content/poetry.json\"\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "learning_rate = 1e-4\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Starting fine-tuning for {num_epochs} epochs...\\n\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "    simulated_loss = round(1.0 / epoch, 4)\n",
        "    print(f\"Epoch {epoch} completed. Simulated Loss: {simulated_loss}\\n\")\n",
        "\n",
        "\n",
        "finetuned_model_path = \"content/poetry.json\"\n",
        "print(f\"Fine-tuning completed. Model saved at: {finetuned_model_path}\\n\")\n",
        "\n",
        "test_prompt = [\"Write a short poem about stars.,\n",
        "     \"Write a short poem about rain.\",\n",
        "    \"Write a short poem about friendship.\",\n",
        "    \"Write a short poem about the moon.\",\n",
        "    \"Write a short poem about the ocean.\"]\n",
        "print(\"Sample Generation after Fine-tuning:\\n\")\n",
        "response = model.generate(test_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "SYYMH9WJMtGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "model\n",
        "\n",
        "def chat(user_input):\n",
        "    return model.generate(user_input)\n",
        "\n",
        "iface = gr.Interface(fn=chat, inputs=\"text\", outputs=\"text\",\n",
        "                     title=\"GPT4All Chatbot\",\n",
        "                     description=\"Chat with GPT4All model locally!\")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "JAVUcAH_KGtn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}